#!/usr/bin/env python

# By Jason Ladner

#This script requires:
#    1. A fastq file generated by cut_ref_fastq. py or similar. This should include one read per base in the genome (with the exception of the very end), with the names as 'contig_position'
#    2. Reference fasta file used to generate the fastq
#    3. gff file for the reference fasta with info on all annotations in the genome

from __future__ import division
import sys, optparse, os, pysam, math
from subprocess import Popen, PIPE
from Bio.Seq import Seq
from Bio.Alphabet import generic_dna
import numpy as np

def main():

    #To parse command line
    usage = "usage: %prog [options] bam1 [bam2 ...]"
    p = optparse.OptionParser(usage)
    
    #Input/output files
    p.add_option('-q', '--fastq', help='fastq file generated by cut_ref_fastq. py or similar [None, REQ]')
    p.add_option('-r', '--ref', help='Fasta file that was used to construct fastq. [None, REQ]')
    p.add_option('-g', '--gff', help='gff file with annotations for the reference [None, REQ]')
    p.add_option('-o', '--out', help='Base name for output files. Output files will be written to the current working directory. [new_consensus]')
    p.add_option('-s', '--sam', help='Optional starting place [None]')
    p.add_option('-b', '--bam', help='Optional starting place [None]')
    p.add_option('-p', '--procs', type='int', default=1, help='Number of processors to use when mapping reads [1]')
    p.add_option('-d', '--scoreDiffMin', type='int', default=0, help='Score difference between AS and XS must be be less than this for a region not to be repetitive [0]')
    p.add_option('-t', '--types', default='gene', help='comma separated list of the typs of features to include in the output [gene]')

    #For samtools
#    p.add_option('--mapQ', type='int', default=10, help='Minimum mapping quality for a read to be used in the pileup generation [10]')
    
    
    opts, args = p.parse_args()

    #Change all filenames to their absolute path versions
    if opts.ref: opts.ref=os.path.abspath(opts.ref)
    if opts.fastq: opts.fastq=os.path.abspath(opts.fastq)
    if opts.gff: opts.gff=os.path.abspath(opts.gff)
    if opts.sam: opts.sam=os.path.abspath(opts.sam)
    if opts.bam: opts.bam=os.path.abspath(opts.bam)

    #Make alignment, if not provided
    if not opts.sam and not opts.bam: opts.sam = bowtie2_index_align(opts)
    #Make, sort and index bam, if not provided
    if not opts.bam: opts.bam = make_sort_index_bam(opts)
    #Parse through bam to ID repeat regions
    repeat_bases = parse_bam(opts)
    make_outputs(repeat_bases, opts)
###-----------------End of main()--------------------------->>>

def rep_per_gene(repeat_bases, opts):
    
    #Open gff file with annotation info
    fin = open(opts.gff, "r")
    #Prep list with list of feature types to extract from gff
    types_list = opts.types.split(',')

    #Open output file for writing
    fout=open('%s_d%d_repgenes.txt' % (opts.out, opts.scoreDiffMin), 'w')
    fout.write("Contig\tLocus_Tag\tStart\tStop\t#RepBases\tPercRepBases\t#RepBases_mid80\tPercRepBases_mid80\tInfo\n")
    
    #Step through gff and extract info for features
    for line in fin:
        if not line.startswith('#'):
            cols=line.strip().split('\t')
            if cols[2] in types_list:
                chrom=cols[0]
                #List of reference positions, 1-based, for the entire feature
                full_feat = range(int(cols[3]), int(cols[4])+1)
                #List of reference positions, 1-based, for the midddle 85% of the feature
                bases_to_trim = int(math.ceil(len(full_feat)*0.1))
                trim_feat = full_feat[bases_to_trim:-bases_to_trim]
                
                #Get info for output
                num_rep_full = len(set(full_feat).intersection(set(repeat_bases[chrom])))
                num_rep_trim = len(set(trim_feat).intersection(set(repeat_bases[chrom])))
                
                #Write to output
                fout.write('%s\t%s\t%s\t%s\t%d\t%.2f\t%d\t%.2f\t%s\n' % (chrom, find_locus_tag(cols[8]),cols[3], cols[4], num_rep_full, num_rep_full/len(full_feat)*100, num_rep_trim, num_rep_trim/len(trim_feat)*100, cols[8]))
    fout.close()
    fin.close()

def find_locus_tag(info_string):
    cols=info_string.split(';')
    for each in cols:
        if each.startswith('locus_tag'):
            return each.split('=')[-1]
    return 'NA'


def make_outputs(repeat_bases, opts):
    #Write out file with one line per repetitive base
    fout=open('%s_d%d_repbases.txt' % (opts.out, opts.scoreDiffMin), 'w')
    fout.write("Contig\tPosition\n")
    fout_bed=open('%s_d%d_repregions.bed' % (opts.out, opts.scoreDiffMin), 'w')
    for each, alist in repeat_bases.iteritems():
        start=0
        stop=0
        for pos in sorted(alist):
            fout.write('%s\t%d\n' % (each, pos))
            if not start and not stop:
                start=pos
                stop=pos
            elif pos-stop==1: stop=pos
            else:
                fout_bed.write("%s\t%d\t%d\n" % (each, start-1, stop))
                start=0
                stop=0
    fout.close()
    fout_bed.close()
    
    #Calculate # and % repetitive bases per gene
    rep_per_gene(repeat_bases, opts)

def parse_bam(opts):
    rep_bases_dict={}
    readbam = pysam.AlignmentFile(opts.bam, "rb")
    for read in readbam.fetch():
        #Quick check to make sure the read is mapped, they all should be for the anticipated usage of this script
        if read.is_unmapped: print read.query_name
        else:
            #If there is a secondary alignment
            if read.has_tag('XS'):
                if int(read.get_tag('AS'))-int(read.get_tag('XS')) <= opts.scoreDiffMin:
                    contig = '_'.join(read.query_name.split('_')[:-1])
                    pos = read.query_name.split('_')[-1]
                    if contig not in rep_bases_dict: rep_bases_dict[contig]=[]
                    rep_bases_dict[contig].append(int(pos))
            elif int(read.get_tag('AS')) != 0: print read.query_name, read.get_tag('AS')
    return rep_bases_dict

##!!! Expecting fastq quality scores to be 33-offset
def bowtie2_index_align(opts):
    
    #Make index for reference
    cmd='bowtie2-build %s ref_index' % (opts.ref)
    print cmd
    os.popen(cmd)
    
    #Make string for output sam file name
    sam_name='%s_aligned.sam' % opts.out
    
    #Align reads as unpaired
    #Using --ignore-quals, in part because the quality scores for the input at meaningless. This also makes it easier to understand alignment scores
    cmd='bowtie2 -p %d --phred33 -N 1 -x ref_index -U %s -S %s --ignore-quals' % (opts.procs, opts.fastq, sam_name)
    print cmd
    unpaired_bowtie=Popen(cmd, shell=True, stdout=PIPE, stderr=PIPE)
    unpaired_bowtie.wait()
    return sam_name

###----------End of bowtie2 functions----------------------------------------

def make_sort_index_bam(opts):
    #Make new faidx for current reference
    cmd='samtools faidx %s' % opts.ref
    print cmd
    faidx=Popen(cmd, shell=True, stdout=PIPE, stderr=PIPE)
    faidx.wait()
    
    #Make bam from sam, and sort the bam
    sam_prefix='.'.join(opts.sam.split('/')[-1].split('.')[:-1])
    bam_name='%s_sorted.bam' % sam_prefix
    cmd='samtools view -bS %s | samtools sort -m 800000000 - %s' % (opts.sam, sam_prefix + '_sorted')
    print cmd
    make_bam=Popen(cmd, shell=True, stdout=PIPE, stderr=PIPE)
    make_bam.wait()
    
    #index bam for easy access
    cmd='samtools index %s' % bam_name
    print cmd
    index=Popen(cmd, shell=True, stdout=PIPE, stderr=PIPE)
    index.wait()
    
    return bam_name


####-------------------->>>>
#####---Anything below here may not actually be used--------------->>>>>

def good_qual(index_quals, min_qual, offset):
    index_quals=[ord(x)-offset for x in index_quals.strip()]
    if np.average(index_quals)>=min_qual: return True
    else: return False
    
def quality_filter(bases, quals, opts):
    new_bases=[]
    new_quals=[]
    for index in range(len(bases)):
        if ord(quals[index])-opts.offset >= opts.baseQual:
            new_bases.append(bases[index])
            new_quals.append(quals[index])
    return new_bases, new_quals


def rev_comp(seq):
    dna = Seq(seq, generic_dna)
    return str(dna.reverse_complement())

#Use this to delete some files, given that those files exist    
def delete_files(*done_files):
    for to_remove in done_files:
        if os.path.isfile(to_remove):
            os.remove(to_remove)

    
def make_info_dict(info_file):
    idict={}
    fin=open(info_file, 'r')
    for line in fin:
        cols=line.strip().split('\t')
        if cols[0] not in idict: idict[cols[0]]=[]
        idict[cols[0]].append(cols[7])
    fin.close()
    return idict


#This function doesn't actually call samtools, but its related
#Creates a new samfile containing only the header and the information for reads that actually mapped to the referene.
#Uses bit 4 of the flag to check if the read is mapped. 
def sam_just_mapped(samfile):
    sam = open(samfile, 'r')
    new_name='%s_onlymapped.sam' % '.'.join(samfile.split('.')[:-1])
    new = open(new_name, 'w')
    for line in sam:
        if line[0] != '@':
            cols=line.split()
            if not int(cols[1]) & 0x4:new.write(line) 
        else: new.write(line)
    sam.close()
    new.close()
    return new_name
    

# will cut fasta name off at the first whitespace
def read_fasta_lists_simple_names(file):
    fin = open(file, 'r')
    count=0

    names=[]
    seqs=[]
    seq=''
    for line in fin:
        line=line.strip()
        if line and line[0] == '>':                #indicates the name of the sequence
            count+=1
            names.append(line[1:].split()[0])
            if count>1:
                seqs.append(seq)
            seq=''
        else: seq +=line
    seqs.append(seq)

    return names, seqs


#writes a new fasta file
def write_fasta(names, seqs, new_filename):
    fout=open(new_filename, 'w')
    for i in range(len(names)):
        fout.write(">%s\n%s\n" % (names[i], seqs[i]))
    fout.close()

def read_fasta_dict_simple_names(file):
    names, seqs = read_fasta_lists_simple_names(file)
    fasta_dict = dict(zip(names, seqs))
    return fasta_dict

###------------END of functions used in building new consensus from pileup----------------------------


        
        
###------------->>>

if __name__ == "__main__":
    main()
